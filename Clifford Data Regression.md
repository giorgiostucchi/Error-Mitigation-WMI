Clifford data regression (CDR) is a learning-based quantum error mitigation technique in which an error mitigation model is trained with quantum circuits thatÂ _resemble_Â the circuit of interest, but which are easier to classically simulate.

This error mitigation strategy is designed for application at the gate level and is relatively straightforward to apply on gate-based quantum computers. CDR primarily consists of creating a training data setÂ $\{(X_{\phi_i}^{\text{error}}, X_{\phi_i}^{\text{exact}})\}$, whereÂ $X_{\phi_i}^{\text{error}}$Â and Â  $X_{\phi_i}^{\text{exact}}$ are the expectation values of an observableÂ ğ‘‹Â for a stateÂ $|\phi_i\rangle$Â under error and error-free conditions, respectively.

This method includes the following steps:

1. **Choose Near-Clifford Circuits for Training.**Â Near-Clifford circuits are selected due to their capability to be efficiently simulated classically, and are denoted byÂ $S_\psi=\{|\phi_i\rangle\}_i$.
2. **Construct the Training Set.**Â The training setÂ $\{(X_{\phi_i}^{\text{error}}, X_{\phi_i}^{\text{exact}})\}$Â is constructed by calculating the expectation values ofÂ ğ‘‹Â for each stateÂ Â $|\phi_i\rangle$Â inÂ $S_\psi$, on both a quantum computer (to obtain$X_{\phi_i}^{\text{error}}$) and a classical computer (to obtainÂ $X_{\phi_i}^{\text{exact}}$).
3. **Learn the Error Mitigation Model.**Â A modelÂ $f(X^{\text{error}}$, a)Â forÂ $X^{exact}$Â is defined and learned. Here,Â ğ‘Â is the set of parameters to be determined. This is achieved by minimizing the distance between the training set, as expressed by the following optimization problem:Â $a_{opt} = \underset{a}{\text{argmin}} \sum_i \left| X_{\phi_i}^{\text{exact}} - f(X_{\phi_i}^{\text{error}},a) \right|^2$.Â In this expression,Â $ğ‘_{opt}$Â are the parameters that minimize the cost function.
4. **Apply the Error Mitigation Model.**Â Finally, the learned modelÂ $f(X^{\text{error}}, a_{opt})$Â is used to correct the expectation values ofÂ ğ‘‹Â for new quantum states, expressed asÂ $X_\psi^{\text{exact}} = f(X_\psi^{\text{error}}, a_{opt})$.

The effectiveness of this method has been demonstrated on circuits with up to 64 qubits and for tasks such as estimating ground-state energies. However, its performance is dependent on the task, the system, the quality of the training data, and the choice of model.

![[Pasted image 20240610115227.png]]

Near-Clifford approximations of the actual circuit are simulated, without noise, on a classical simulator (circuits can be efficiently simulated classically) and executed on the noisy quantum computer (or a noisy simulator). These results are used as training data to infer the zero-noise expectation value of the error miitigated original circuit, that is finally run on the quantum computer (or noisy simulator).



## Problem setup

To use CDR, we callÂ need four â€œingredientsâ€:

1. A quantum circuit to prepare a stateÂ ğœŒ.
2. A quantum computer or noisy simulator to return aÂ `mitiq.QuantumResult`Â fromÂ ğœŒ.
3. An observableÂ ğ‘‚Â which specifies what we wish to compute viaÂ Tr(ğœŒğ‘‚).
4. A near-Clifford (classical) circuit simulator.

The quantum circuit must be compiled into a gateset in which the only non-Clifford gates are single-qubit rotations around theÂ ğ‘Â axis:Â $R_Z(\theta)$.

The CDR method creates a set of â€œtraining circuitsâ€ which are related to the input circuit and are efficiently simulatable. These circuits are simulated on a classical (noiseless) simulator to collect data for regression.

To use CDR at scale, an efficient near-Clifford circuit simulator must be specified.


## Advantages

The main advantage of CDR is that it can be applied without knowing the specific details of the noise model. Indeed, in CDR, the effects of noise are indirectlyÂ _learned_Â through the execution of an appropriate set of test circuits. In this way, the final error mitigation inference tends to be tuned to the used backend.

This self-tuning property is even stronger in the case ofÂ _variable-noise-CDR_, i.e., when using theÂ `scale_factors`Â option inÂ [`execute_with_cdr()`](https://mitiq.readthedocs.io/en/latest/apidoc.html#mitiq.cdr.cdr.execute_with_cdr "mitiq.cdr.cdr.execute_with_cdr"). In this case, the final error mitigated expectation value is obtained as a linear combination of noise-scaled expectation values. This is similar toÂ [Zero-Noise Extrapolation](https://mitiq.readthedocs.io/en/latest/guide/zne-5-theory.html)Â but, in CDR, the coefficients of the linear combination are learned instead of being fixed by the extrapolation model.

## Disadvantages

The main disadvantage of CDR is that the learning process is performed on a suite of test circuits which onlyÂ _resemble_Â the original circuit of interest. Indeed, test circuits areÂ _near-Clifford approximations_Â of the original one. Only when the approximation is justified, the application of CDR can produce meaningful results. Increasing theÂ `fraction_non_clifford`Â option inÂ [`execute_with_cdr()`](https://mitiq.readthedocs.io/en/latest/apidoc.html#mitiq.cdr.cdr.execute_with_cdr "mitiq.cdr.cdr.execute_with_cdr")Â can alleviate this problem to some extent. Note that, the largerÂ `fraction_non_clifford`Â is, the larger the classical computation overhead is.

Another relevant aspect to consider is that, to apply CDR in a scalable way, a valid near-Clifford simulator is necessary. Note that the computation cost of a valid near-Clifford simulator should scale with the number of non-Clifford gates, independently from the circuit depth. Only in this case, the learning phase of CDR can be applied efficiently.

**Notes**: 
- 

**Open Questions**:
 - [ ]  Check definition of Clifford Gates

### References
- [What is the theory behind CDR? ](https://mitiq.readthedocs.io/en/latest/guide/cdr-5-theory.html)
- Â [Error mitigation with Clifford quantum-circuit data](https://quantum-journal.org/papers/q-2021-11-26-592/pdf/) (yet to read)
- Â [Unified approach to data-driven quantum error mitigation](https://journals.aps.org/prresearch/pdf/10.1103/PhysRevResearch.3.033098) (yet to read)