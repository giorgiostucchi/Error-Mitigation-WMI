{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "remove_cell"
    ]
   },
   "source": [
    "# Measurement Error Mitigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit import QuantumCircuit, QuantumRegister\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qiskit_aer.noise import NoiseModel, pauli_error\n",
    "\n",
    "#Simple noise model, which randomly flips each bit in an output with probability p.\n",
    "def get_noise(p):\n",
    "    error_meas = pauli_error([('X',p), ('I', 1 - p)])\n",
    "\n",
    "    noise_model = NoiseModel()\n",
    "    noise_model.add_all_qubit_quantum_error(error_meas, \"measure\") # measurement error is applied to measurements\n",
    "        \n",
    "    return noise_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(n_qubits):\n",
    "    total_states = 2**n_qubits\n",
    "    states = [format(i, f'0{n_qubits}b') for i in range(total_states)]\n",
    "    confusion_matrix = np.zeros((total_states, total_states))\n",
    "    return states, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '01', '10', '11']\n",
      "00 becomes {'11': 1063, '01': 9084, '10': 9033, '00': 80820}\n",
      "01 becomes {'10': 989, '00': 9192, '11': 9184, '01': 80635}\n",
      "10 becomes {'01': 1003, '11': 8945, '00': 9107, '10': 80945}\n",
      "11 becomes {'00': 1039, '10': 9206, '01': 9174, '11': 80581}\n",
      "\n",
      "Confusion Matrix:\n",
      "[[0.808200 0.090840 0.090330 0.010630]\n",
      " [0.091920 0.806350 0.009890 0.091840]\n",
      " [0.091070 0.010030 0.809450 0.089450]\n",
      " [0.010390 0.091740 0.092060 0.805810]] \n",
      "\n",
      "Mitigator:\n",
      "[[1.269343 -0.142975 -0.141642 0.015273]\n",
      " [-0.144819 1.272761 0.017107 -0.145048]\n",
      " [-0.142834 0.016330 1.267142 -0.140638]\n",
      " [0.016439 -0.144924 -0.144886 1.273371]]\n"
     ]
    }
   ],
   "source": [
    "from qiskit_aer.backends import AerSimulator\n",
    "import scipy.linalg as la\n",
    "\n",
    "shots = 100000\n",
    "n_qubits = 2\n",
    "\n",
    "states, confusion_matrix = initialize(n_qubits)\n",
    "\n",
    "print(states)\n",
    "\n",
    "for i, state in enumerate(states):\n",
    "    qc = QuantumCircuit(n_qubits,n_qubits)\n",
    "    if state[0]=='1':\n",
    "        qc.x(1) # qiskit has inverted notation!!!!\n",
    "    if state[1]=='1':\n",
    "        qc.x(0)  \n",
    "    qc.measure(qc.qregs[0],qc.cregs[0])  # [0] refers to the first register (to specify qubit, add [n])\n",
    "    #print(qc)\n",
    "    noise = get_noise(0.1)\n",
    "    simulator = AerSimulator(noise_model = noise)\n",
    "    counts = simulator.run(qc,shots=shots).result().get_counts(qc)\n",
    "    print(state +' becomes',counts)\n",
    "\n",
    "    # Update the confusion matrix\n",
    "    for measured_state, count in counts.items():\n",
    "        j = states.index(measured_state)\n",
    "        confusion_matrix[i, j] += count\n",
    "\n",
    "# Normalize the confusion matrix\n",
    "confusion_matrix /= shots    \n",
    "\n",
    "\n",
    "np.set_printoptions(formatter={'float': '{:0.6f}'.format})\n",
    "\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix, \"\\n\")\n",
    "\n",
    "mitigator = la.inv(confusion_matrix)\n",
    "\n",
    "print(\"Mitigator:\")\n",
    "print(mitigator)  \n",
    "\n",
    "#\"\"\"\n",
    "#One could in theory find the confusion matrix and its inverse based on purely theoretical considerations of the error model, \n",
    "#or do it statistically as shown here. On hardware, probably the latter is better if the noise characterization isn't sufficiently accurate.\n",
    "#\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.optimize\n",
    "import numpy.typing as npt\n",
    "\n",
    "def closest_positive_distribution(\n",
    "    quasi_probabilities: npt.NDArray[np.float64],\n",
    ") -> npt.NDArray[np.float64]:\n",
    "    \"\"\"Given the input quasi-probability distribution returns the closest\n",
    "    positive probability distribution (with respect to the total variation\n",
    "    distance).\n",
    "\n",
    "    Args:\n",
    "        quasi_probabilities: The input array of real coefficients.\n",
    "\n",
    "    Returns:\n",
    "        The closest probability distribution.\n",
    "    \"\"\"\n",
    "    quasi_probabilities = np.array(quasi_probabilities, dtype=np.float64)\n",
    "    init_guess = quasi_probabilities.clip(min=0)\n",
    "    init_guess /= np.sum(init_guess)\n",
    "\n",
    "    def distance(probabilities: npt.NDArray[np.float64]) -> np.float64:\n",
    "        return np.linalg.norm(probabilities - quasi_probabilities)\n",
    "\n",
    "    num_vars = len(init_guess)\n",
    "    bounds = scipy.optimize.Bounds(np.zeros(num_vars), np.ones(num_vars))\n",
    "    normalization = scipy.optimize.LinearConstraint(np.ones(num_vars).T, 1, 1)\n",
    "    result = scipy.optimize.minimize(\n",
    "        distance,\n",
    "        init_guess,\n",
    "        bounds=bounds,\n",
    "        constraints=normalization,\n",
    "    )\n",
    "    if not result.success:\n",
    "        raise ValueError(\n",
    "            \"REM failed to determine the closest positive distribution.\"\n",
    "        )\n",
    "    return result.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empirical probabilities: [0.410000 0.092210 0.089900 0.407890]\n",
      "Mitigated quasi-probabilities: [0.500743 0.000360 -0.000505 0.499747]\n",
      "Closest positive probabilities: [0.500460 0.000077 0.000000 0.499464]\n"
     ]
    }
   ],
   "source": [
    "#now we define an arbitrary circuit and apply the mitigation \n",
    "\n",
    "shots = 100000\n",
    "\n",
    "qc = QuantumCircuit(n_qubits,n_qubits)\n",
    "qc.h(0)\n",
    "qc.cx(0,1) \n",
    "qc.measure(qc.qregs[0],qc.cregs[0])\n",
    "#print(qc)\n",
    "simulator = AerSimulator(noise_model = noise) # Use same noise model as for calibration !!!\n",
    "counts = simulator.run(qc,shots=shots).result().get_counts(qc)\n",
    "# Normalize the counts to get probabilities\n",
    "probabilities = {k: v / shots for k, v in counts.items()}\n",
    "\n",
    "# Sort the probabilities dictionary by its keys (binary strings converted to integers)\n",
    "probability_vector = np.array([probability for state, probability in sorted(probabilities.items(), key=lambda x: int(x[0], 2))])\n",
    "\n",
    "print(\"Empirical probabilities:\", probability_vector)\n",
    "\n",
    "mitigated_probabilities = np.dot(mitigator, probability_vector)\n",
    "print(\"Mitigated quasi-probabilities:\", mitigated_probabilities)\n",
    "\n",
    "closest_probabilities = closest_positive_distribution(mitigated_probabilities)\n",
    "print(\"Closest positive probabilities:\", closest_probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "\n",
    "def sample_probability_vector(\n",
    "    probability_vector: npt.NDArray[np.float64], samples: int\n",
    ") -> List[List[int]]:\n",
    "    \"\"\"Generate a number of samples from a probability distribution as\n",
    "    bitstrings.\n",
    "\n",
    "    Args:\n",
    "        probability_vector: A probability vector.\n",
    "        samples: Number of samples to generate.\n",
    "\n",
    "    Returns:\n",
    "        A list of sampled bitstrings.\n",
    "    \"\"\"\n",
    "    # sample using the probability distribution given\n",
    "    num_values = len(probability_vector)\n",
    "    choices = np.random.choice(num_values, size=samples, p=probability_vector)\n",
    "\n",
    "    # convert samples to binary strings\n",
    "    bit_width = int(np.log2(num_values))\n",
    "    binary_repr_vec = np.vectorize(np.binary_repr)\n",
    "    binary_strings = binary_repr_vec(choices, width=bit_width)\n",
    "\n",
    "    # convert binary strings to lists of integers\n",
    "    bitstrings = [list(map(int, list(bs))) for bs in binary_strings]\n",
    "\n",
    "    return bitstrings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1, 1], [1, 1], [0, 0], [1, 1], [1, 1], [1, 1], [1, 1], [1, 1], [0, 0], [1, 1]]\n"
     ]
    }
   ],
   "source": [
    "#if we are interested in generating some samples from the mitigated distribution\n",
    "samples = 10\n",
    "bitstrings = sample_probability_vector(closest_probabilities, samples)\n",
    "print(bitstrings)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
